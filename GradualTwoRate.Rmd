---
title: "Do small errors lead to more implicit motor adaptation?"
csl: journal-of-vision.csl
link-citations: yes
output:
  word_document: default
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
bibliography: bibliography.bib
---

In this document we pre-process and analyze data and make figures for a project where we test the common assumption that introducing a visuomotor perturbation gradually leads to more implicit learning. In 5 groups of people, including a cohort of participants with mid cerebellar damage, and older participanrs (age-matched controls) doing various paradigms in within-subject designs, we still failed to confirm this.

The data for this project is available from OSF.

This RStudio Project uses `renv` in an attempt to make sure the same (versions of) packages are used here as we used when we originally wrote the scripts. This probably took some time when starting this up. It also means that all those packages are installed in the project folder, so after being done with the project, you might want to free up some disk space by removing it.

Then we access all our custom functions:

```{r setup, echo=FALSE}
# has some functions to process the raw data to get it all into a shared format ready for OSF:

# this collected the data, and partially unified variables/format:
# sources('R/data.R')
# the output is provided on OSF, code left as a record

# this is for (pre)processing the data, and it completes the standardization of data:
source('R/process.R')

# this has some common functions:
# functions decsribing groups, styles, etc
# getting data from OSF
# selecting trials & participants
# parsing data (normalizing, blocking, etc)
source('R/common.R')

# this has functions to make figures:
source('R/figures.R')

# this file has functions to run and test the two-rate model:
source('R/models.R')
# also has an asymptotic decay model for learning rates and an unused one-rate model

# this file has functions that reproduce the statistical analyses:
source('R/statistics.R')
```

The first thing to do is to download all the data. There is a function for this, which has some options, but by default it downloads all the data as 5 zip files (if not there) and unzips these.

```{r download-data}
downloadOSFdata()
```

Then we process the reaching data to get reach deviations for every trial. The function call below does all of this in a standardized manner across all 5 groups and makes sure the output format is the same for all 3 codebases, so we can run the same models and stats on all of them. All of this happens with functions in the `process.R` file. Feel free to try other ways to process the data, but make sure the output format remains the same - or be prepared to change lots of code down the road.

Right now, the reach deviation at a quarter of the home-target distance is used as a cut-off point, using the first sample beyond this distance. There is built in functionality for other cut-off points, although we didn't test it on this data. For example, the first peak in the velocity profile could also be used (based on a smooth-spline interpolation), or a set distance in centimeters.

```{r process, eval=FALSE}

# each of these commands takes a while
# since the standard output is already downloaded from OSF, this step is skipped

# take the raw reaches and get reach a deviation per trial:
#getReachDeviations()

# fits the two-rate model to each participants and the group average:
#getGroupFits(groups=getInfo()$group)

# bootstrap two-rate model fit parameter values by resampling participants within each group 1000 times: 
#bootstrapFits(groups=getInfo()$group)

# calculate fit quality for the bootstrapped parameter fits:
#modelMSEs(groups=getInfo()$group)

# parameter recovery simulation using the younger control group in the second experiment as middle ground:
#parameterRecoverySimulation()

# feel free to redo any of these to check if you get the same values, 
# or if you have changed the way that reach deviations are determined, which may change results (we didn't check)

```

The data folders for each of the 5 groups now have 2 extra files: one with reach deviations for all participants when doing the abrupt condition and one when doing the gradual condition.

# Two-rate model

The two rate model explains adaptation using a "slow" and a "fast" process. The reach deviation on a trial $t$ is simply the summed output of the two processes:

$X_t = F_t + S_t$

The output of each of the two processes learns from errors based on its' learning rate and also retains some of what its' learned with a retention rate:

$F_t = l^f \cdot e_{t-1} + r^f \cdot F_{t-1}$

$S_t = l^s \cdot e_{t-1} + r^s \cdot S_{t-1}$

To ensure that the fast process is faster than the slow process, model fits are usually constrained such that $l^f > l^s$ and also $r^f < r^s$. Further constraints keep the solution stable.

We start the model with both processes at 0, and in order to obtain a good fit, a perturbation schedule with an aligned phase, long initial rotation, short counter rotation and a phase with error-clamped feedback is usually used. During error-clamped feedback, the errors are artificially set to 0 which means that both processes can only rely on their retention to contribute to any reach deviations.

## Explicit and implicit map onto fast and slow

Some studies suggest that explicit and implicit learning map onto the fast and slow process [@McDougle2015]. In this paper we test some of the predictions that follow from this, and further rely on the assumption that gradually introducing a rotation leads to more implicit adaptation.

# Experiment 1: Rotation Size and Introduction

If the fast process corresponds to explicit learning, this leads to a number of predictions. First, we can test the effect of the magnitude of the rotation, which we do here. Since we found little to no explicit learning with a 30 degree rotation, and significant explicit learning with a 60 degree rotation previously [@Modchalingam2019] we use these two rotations here. Second, if a gradual introduction of the rotation leads to more implicit learning, this should dampen the fast process (and boost the slow process). Finally, if a gradual and abrupt rotation lead to the same amount of adaptation by the end of training, the rebound in an error-clamp phase should be different if the fast and slow process contribute differently in these two groups.

## Data Figure

First, we look at the group data, by plotting it. Then we check the asymptotic level of adaptation, and the absolute size of the rebounds in the error-clamp phases using first an ANOVA and then t-tests. Finally we fit the two-rate model to compare fitted parameter values between conditions.

```{r fig3, fig.width=4, fig.height=7, fig.cap="**Figure 3:** reach deviations..."}
plotExpBehavior(exp=1, target='inline', version=3)
```

Mostly, when comparing the two conditions (with ramped in purple and abrupt in orange) there seems not to be an effect of how the rotation is introduced on the adaptation at the end of the initial rotation, or in the error clamped phase. There might be an effect of rotation size on rebound (reach deviations in the error-clamped phase).

## Order Effects

However, before investigating any of these question, we need to make sure there is no order effect. Since these are all within-subject experiments, participants do both conditions, and it could be that first learning the rotation when it is ramped, might help learn it when introduced abruptly in the second session. We fit a simple asymptotic decay model with two parameters: an asymptotic level of adaptation (N0) and a learning rate (lambda), which expresses how quickly the asymptotic level of adaptation is achieved. The models are fit on normalized reach deviations, so that they are all scaled between 0 and 1 (instead of between 0 and 30 or 0 and 60)  We can only get learning rates from the abrupt conditions, which means we can compare them between the participants who do abrupt first and those who did ramped first.

```{r exp1_ordereffects}
testOrderEffects(exp=1)
```

There is no effect of first condition across the two groups, no effect of group and no interaction. We can now combine all data to look into differences between abrupt and ramped conditions.

## Asymptotic aptation and rebound

Let's do our planned ANOVA's. First one on the whole data set, a repeated measures ANOVA on normalized reach deviation, using block (rotated or clamped) and condition (abrupt or ramped) as within-subject factors and rotation size (30 or 60 degrees) as between-subjects factor.

```{r exp1_blockanova}
doExpANOVAs(exp=1)
```

Not surprisingly, there is an effect of block (rotated or clamped) and as we suspected from looking at the figure there is an effect of group, which interacts with block. This can be explained by a larger rebound in the 30 degree group, which makes sense if learning is more implicit with 30 degrees than with 60 degrees. However, the main take-away is that there is no main effect of condition, nor does condition interact with any of the other variables. This would mean that the way the rotation is introduced (abrupt or ramped) has no effect on the asymptotic level of adaptation here, nor does it affect the size of the spontaneous rebound.

## Equivalance of conditions

We take this one step further and test, if --across the whole experiment-- the difference between reach deviations in the abrupt and ramped conditions (separate for each block) may even support the null hypothesis. To do this we run a simple Bayesian analysis:

```{r exp1_blockBF_overall}
conditionBayesFactors(exp=1)
```

Both using the data from the rotated block (BF=0.2017), and from the clamped block (BF=0.1807), there is moderate support for the null hypothesis.

Split by group, we get these numbers:


```{r exp1_blockBF_bygroup}
conditionBayesFactors(groups=getInfo()$group[which(getInfo()$experiment==1)])
```

All of these are below 1/3, so each condition provides moderate support for the null-hypothesis: there is no difference in asymptotic adaptation or rebound depending on how the rotation is introduced. Since there is no difference in asymptotic adaptation, the absence of any difference in rebounds means there is no effect of how the rotation is introduced (abrupt or ramped) on implicit adaptation.

## Model fits

Now we also want to see if the two-rate model is different between the abrupt and ramped conditions. First we look at the group fits.

```{r fig4, fig.width=6, fig.height=7, fig.cap="**Figure 4:** two-rate model fits..."}
plotExpModelFits(exp=1)
```

## Differences in fitted model parameters

We now look at the model parameter values to see if there is any difference in the parameter values between ramped and abrupt conditions (Fig 5). We resample participants 1000 times, and fit the model to the average reach deviations in both the abrupt and gradual conditions. Dots are individual participants' parameters, density lines show distributions of parameter values. In the small inset, we see the distribution (density curve) and 95% confidence interval (purple shaded area). This can be compared to the 95% confidence interval of recovered parameters (gray shaded area). We see that the 95% confidence interval for the differences in parameter values includes the 95% confidence interval of recovered parameters in both groups, for all 4 parameters. This means there is no difference in fit parameter values.

```{r fig5, fig.width=7, fig.height=4, fig.cap="**Figure 5:** parameter differences..."}
plotExpModelParameters(exp=1)
```

Here are the confidence intervals of the differences:

```{r parameterCIs}
conditionParameterDiffs(exp=1)
```

Zero is included in all confidence intervals, which we interpret as no difference between the abrupt and gradual conditions in each of the rotations.

**DO WE NEED THE PARAMETER RECOVERY CONFIDENCE INTERVALS AS WELL?**

**Probably yes!**

# Experiment 2: Mild Cerebellar Ataxia and Age

If the cerebellum implements the majority of implicit adaptation, then people with lesions in the cerebellum should rely more on explicit adaptation compared to age-matched control. If older adults (can) rely less on cognitive capacities (because of age-related cognitive decline) then they should rely more on implicit adaptation compared to younger adaults. Here we test a population with mild cerebellar ataxia. Since most people with cerebellar ataxia are older, we also compare their age-matched controls with younger adults.

Let's have a look at the data:


```{r fig6, fig.width=4, fig.height=7, fig.cap="**Figure 6:** reach deviations..."}
plotExpBehavior(exp=2, target='inline', version=3)
```

Notice again that instead of a counter rotation (which would lead to errors close to 90 degrees: possibly hard to handle by people with mild cerebellar ataxia) there is another aligned phase.

## Order effects

As before, this is a within-subject experiment (all participants do both the ramped and the abrupt condition), and we want to make sure there is no order effect.

```{r exp2_ordereffects}
testOrderEffects(exp=2)
```

Just as in the first experiment, there is no effect of group, no effect of order, and there is no interaction either. We can now combine the data and ignore task order in further analyses.

## Asymptotic adaptation and rebounds

In the smaller graphs at the bottom of Figure 6, it again seems like there is no effect of group (mild cerebellar ataxia, age-matched controls or younger controls) nor any effect of condition (abrupt or ramped) on either the asymptotic level of adaptation in the first rotated phase or on the size of the rebound (reach deviations in the error-clamped phase).

Let's check this with an ANOVA:

```{r exp2_block_anova}
doExpANOVAs(exp=2)
```

There is a main effect of block (not surprising), but no other effects are significant. That means that we _can not reject_ the null hypothesis (that there is no effect of how a rotation is introduced).

## Equivalance of conditions

But, like we did in the rotation-size experiment, we want to see if there is actually support for the null hypothesis:

```{r exp2_blockBF_overall}
conditionBayesFactors(exp=2)
```

For reach deviations in the rotated block, across all three groups in the MCEBAT experiment, there is no real support for the null hypothesis (BF>1/3), but there is in the clamped block. What about the separate groups in exp 2?

```{r exp2_blockBF_bygroup}
conditionBayesFactors(groups=getInfo()$group[which(getInfo()$experiment==2)])
```

The evidence is (of course) less strong for each group, but notice that all Bayes Factors are below 1, so that more powerfull experiments (or larger data sets) would probably lower them. The combined data is fairly clear anyway.

Of course, we can also combine all 5 groups across the two experiments:

```{r bothexp_blockBF_overall}
conditionBayesFactors(exp=0, groups=getInfo()$group)
# uses a trick
# as long as you set groups, they are used
# and as long as you set exp, one overall results is returned
```

With more evidence, the results become only a little clearer: across the board, we have moderate evidence that the way the rotation is introduced does not affect asymptotic level of adaptation, nor on implicit adaptation as measured by the magnitude of the rebound.

## Model fits

For this experiment we also still want to test the two-rate model. First a figure.

```{r fig7, fig.width=6, fig.height=8, , fig.cap="**Figure 7:** two rate model fits..."}
plotExpModelFits(exp=2)
```

We will now look at the parameter values themselves.

```{r fig8, fig.cap="**Figure 8:** model parameter values..."}
plotExpModelParameters(exp=2)
```

The lines depict the distribution of bootstrapped parameters and the dots the parameter values for individual participants. The insets show distributions of differences (gradual - abrupt) as a (purple) density curve, and the corresponding 95% confidence interval as a shaded purple area. Again the gray bars are the 95% confidence intervals from the parameter recovery simulation. We can see that in the mild cerebellar ataxia group there is a difference in the fitted Ls and Lf parameters, and in the age-matched control group there is a differences in the fitted Lf parameter between abrupt and ramped conditions. The slow and fast learning parameters are higher in the ramped condition.

We will check the confidence intervals of the differences in parameter values:

```{r parameter_CIs}
conditionParameterDiffs(exp=2)
```

In the two older groups (mild cerebellar ataxia, and their age-matched controls) the 95% confidence interval of differences in values of parameter `Lf` between abrupt and ramped conditions does not include zero. This shows that in the ramped condition, these groups have a higher learning rate for the fast process. However the slow process shows no differences. In the younger group, the fast learning parameters do show a small difference between the abrupt and ramped conditions, but the 95% confidence interval for this difference overlaps with the 95% confidence interval for that parameter from the parameter recovery simulation, so it is likely due to chance.

# Conclusion

What does all this mean?

Let's list all the main findings:

1. Within each group the rebounds are equivalent, and this can not be explained by different levels of adaptation as these are also equivalent.
2. The 60 degree group has lower rebounds than the 30 degree group, confirming that implicit learning plays a larger role in 30 degree rotation adaptation.
3. Nevertheless, the model parameters show higher slow learning in the ramped condition, but only in the mild cerebellar ataxia group.
4. Counter to all expectations and predictions, both older groups of participants have a higher fast learning parameter in the ramped condition compared to the abrupt condition.

Interpreting this, it could be that the two-rate model has a higher sensitivity to smaller differences between conditions since it fits to all the data, instead of examining selected blocks of trials. The effect of condition on slow learning in the mild cerebellar ataxia group would make sense in that context.

However, the result for the fast learning parameters being higher in the ramped condition in both older groups makes little sense. While we have shown that the two-rate model's slow process does not correspond to implicit learning, we did measure explicit learning, and other studies that did find a good correspondence between the fast process and explicit learning. If we accept this previous work, and the current results, that would imply that ramped perturbation schedules sometimes (in older participants) lead to larger contributions of explicit processes to adaptation, but this does not make sense given vast bodies of research on implicit adaptation.

The more parsimoneous explanation would require a re-evaluation of what the two-rate model really tells us. The first paper describing the model [@Smith2006] finds that the rebound phenomenon can only be explained by assuming there are 2 or more processes involved in motor adaptation, one of which has a different short-term retention rate (and probably learning rate). This does **not** imply however that the brain implements the model as described in this paper, down to all the equations, or that there are really only 2 processes involved in motor adaptation, or that the model's processes necessarily correspond to implicit and explicit adaptation.

Rather, equating implicit and explicit adaptation processes with the slow and fast model processes seems premature. For example, the assumption derived from the hugely popular model that explicit and implicit simply add, combined with measuring only total adaptation and only implicit or explicit processes (usually explicit) will by definition lead to findings that implicit and explicit are somehow additive; either one process compensates for the other [@Miyamoto2020] or they are in competition [Albert et al., unpublished]. While the model works this way, that is obviously a simplification and it does not necessarily mean that the brain works that way. Simple additivity is an unlikely function for the brain to implement.

So we take the stance that work using the two-rate model does show that multiple processes with different memory time-scales are involved in motor adaptation, but not that the brain implements it's equations.

We expected to find different rebounds in abrupt and ramped conditions, which could then be explained by examining the model. However, behavioral performance between groups is equivalent, but still a few model parameters _are_ different between conditions in a few groups. If only our study would find these parameter differences in the fast process, that could be explained as a statistical fluke. However, we largely replicate earlier findings [@Coltman2021] with similar parameter differences. This confirms that, while model parameters are highly recoverable, two-rate model parameter values might not be informative about real differences between conditions or groups.

```{r make_pdf_figures}
target <- 'pdf'

plotExpBehavior(exp=1, target=target, version=3)

plotExpModelFits(exp=1, target=target)

plotExpModelParameters(exp=1, target=target)

plotExpBehavior(exp=2, target=target, version=3)

plotExpModelFits(exp=2, target=target)

plotExpModelParameters(exp=2, target=target)
```


# References
