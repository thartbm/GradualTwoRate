---
title: "Do small errors lead to more implicit motor adaptation?"
output: html_notebook
---

In this document we pre-process and analyze data and make figures for a project where we test the common assumption that introducing a visuomotor perturbation gradually leads to more implicit learning. In 5 groups of people, including a cohort of participants with mid cerebellar damage, and older participanrs (age-matched controls) doing various paradigms in within-subject designs, we still failed to confirm this.

The data for this project is available from OSF.

This RStudio Project uses `renv` in an attempt to make sure the same (versions of) packages are used here as we used when we originally wrote the scripts. This probably took some time when starting this up. It also means that all those packages are installed in the project folder, so after being done with the project, you might want to free up some disk space by removing it.

Then we access all our custom functions:

```{r echo=FALSE}
# has some functions to process the raw data to get it all into a shared format ready for OSF:
# data.R # we don't need them functions anymore

# this has some common functions, for getting data from OSF, and describing the groups:
source('R/common.R')

# this function provides access to information about the participants, e.g. demographics and whether or not they learned:
source('R/participants.R')

# this is for (pre)processing the raw data:
source('R/process.R')

# this is for selecting trials and participants:
source('R/select.R')

# this has functions to make figures:
#source('R/figures.R')

# this file has functions to run and test the two-rate model:
#source('R/model.R')

# this file has functions that reproduce the statistical analyses:
#source('R/statistics.R')
```

The first thing to do is to download all the data. There is a function for this, which has some options, but by default it downloads all the data as 5 zip files (if not there) and unzips these.

```{r}
downloadOSFdata()
```

Then we process the reaching data to get reach deviations for every trial. The function call below does all of this in a standardized manner across all 5 groups and makes sure the output format is the same for all 3 codebases, so we can run the same models and stats on all of them. All of this happens with functions in the `process.R` file. Feel free to try other ways to process the data, but make sure the output format remains the same - or be prepared to change lots of code down the road.

Right now, the reach deviation at a quarter of the home-target distance is used as a cut-off point, using the first sample beyond this distance. There is built in functionality for other cut-off points, although we didn't test it on this data. For example, the first peak in the velocity profile could also be used (based on a smooth-spline interpolation), or a set distance in centimeters.

```{r}
getReachDeviations()
```

The data folders for each of the 5 groups now have 2 extra files: one with reach deviations for all participants when doing the abrupt condition and one when doing the gradual condition.

# Two-rate model

The two rate model explains adaptation using a "slow" and a "fast" process. The reach deviation on a trial $t$ is simply the summed output of the two processes:

$X_t = F_t + S_t$

The output of each of the two processes learns from errors based on its' learning rate and also retains some of what its' learned with a retention rate:

$F_t = l^f \cdot e_{t-1} + r^f \cdot F_{t-1}$

$S_t = l^s \cdot e_{t-1} + r^s \cdot S_{t-1}$

To ensure that the fast process is faster than the slow process, model fits are usually constrained such that $l^f > l^s$ and also $r^f < r^s$. Further constraints keep the solution stable.

We start the model with both processes at 0, and in order to obtain a good fit, a perturbation schedule with an aligned phase, long initial rotation, short counter rotation and a phase with error-clamped feedback is usually used. During error-clamped feedback, the errors are artificially set to 0 which means that both processes can only rely on their retention to contribute to any reach deviations.

## Explicit and implicit map onto fast and slow

Some studies suggest that explicit and implicit learning map onto the fast and slow process [@McDougle2015]. In this paper we test some of the predictions that follow from this, and further rely on the assumption that gradually introducing a rotation leads to more implicit adaptation.

# Experiment 1: Rotation Size and Introduction

If the fast process corresponds to explicit learning, this leads to a number of predictions. First, we can test the effect of the magnitude of the rotation. Since we found little to no explicit learning with a 30 degree rotation, and significant explicit learning with a 60 degree rotation previously [@Modchalingam2019] we use these two rotations here. Second, if a gradual introduction of the rotation leads to more implicit learning, this should dampen the fast process (and boost the slow process). Finally, if a gradual and abrupt rotation lead to the same amount of adaptation by the end of training, the rebound in an error-clamp phase should be different if the fast and slow process contribute differently in these two groups.

First, we look at the group data, by plotting it. Then we check the asymptotic level of adaptation, and the absolute size of the rebounds in the error-clamp phases using first an ANOVA and then t-tests. Finally we fit the two-rate model to compare fitted parameter values between conditions.

```{r}
plotExpPerformance(exp=1, target='inline')
```


# Experiment 2: Mild Cerebellar Ataxia and Age

If the cerebellum implements the majority of implicit adaptation, then people with lesions in the cerebellum should rely more on explicit adaptation compared to age-matched control. If older adults (can) rely less on cognitive capacities (because of age-related cognitive decline) then they should rely more on implicit adaptation compared to younger adaults. Here we test a population with mild cerebellar ataxia. Since most people with cerebellar ataxia are older, we also compare their age-matched controls with younger adults.